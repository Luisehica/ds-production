{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.1 Apache Beam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## append.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing scripts/append.py\n"
     ]
    }
   ],
   "source": [
    "%%file scripts/append.py\n",
    "\n",
    "import argparse\n",
    "import apache_beam as beam\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "from apache_beam.io import ReadFromText\n",
    "from apache_beam.io import WriteToText\n",
    "\n",
    "# define a function for transforming the data \n",
    "class AppendDoFn(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        yield element + \" - Hello World!\"\n",
    "        \n",
    "# set up pipeline parameters \n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--input', dest='input',\n",
    "                    default='gs://dataflow-samples/shakespeare/kinglear.txt')\n",
    "parser.add_argument('--output', dest='output',\n",
    "                    default='gs://dsp_model_store_00/shakespeare/kinglear.txt')\n",
    "known_args, pipeline_args = parser.parse_known_args()\n",
    "pipeline_options = PipelineOptions(pipeline_args)\n",
    "\n",
    "# define the pipeline steps \n",
    "p = beam.Pipeline(options=pipeline_options)\n",
    "lines = p | 'read' >> ReadFromText(known_args.input)\n",
    "appended = lines | 'append' >> beam.ParDo(AppendDoFn())\n",
    "appended | 'write' >> WriteToText(known_args.output)\n",
    "\n",
    "# run the pipeline \n",
    "result = p.run()\n",
    "result.wait_until_finish()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# run locally\n",
    "python3 scripts/append.py"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# run managed\n",
    "python3 scripts/append.py \\\n",
    "    --runner DataflowRunner \\\n",
    "    --project $GOOGLE_PROJECT_ID \\\n",
    "    --region us-central1 \\\n",
    "    --temp_location gs://dsp_model_store_00/tmp/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.2 Batch Model Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataflow_read.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing scripts/dataflow_read.py\n"
     ]
    }
   ],
   "source": [
    "%%file scripts/dataflow_read.py\n",
    "\n",
    "import argparse\n",
    "import apache_beam as beam\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "known_args, pipeline_args = parser.parse_known_args(None)\n",
    "pipeline_options = PipelineOptions(pipeline_args)\n",
    "\n",
    "class ApplyDoFn(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        print(element)\n",
    "\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT\n",
    "        *\n",
    "    FROM\n",
    "        `bigquery-public-data.samples.natality`\n",
    "    ORDER BY\n",
    "        RAND()\n",
    "    LIMIT\n",
    "        5\n",
    "\"\"\"\n",
    "\n",
    "# define the pipeline steps\n",
    "p = beam.Pipeline(options=pipeline_options)\n",
    "data = p | 'Read from BigQuery' >> beam.io.Read(\n",
    "    beam.io.BigQuerySource(query=query, use_standard_sql=True)\n",
    ")\n",
    "scored = data | 'Apply Model' >> beam.ParDo(ApplyDoFn())\n",
    "\n",
    "# run the pipeline\n",
    "result = p.run()\n",
    "result.wait_until_finish()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# run locally\n",
    "python3 scripts/dataflow_read.py --project $GOOGLE_PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>plurality</th>\n",
       "      <th>apgar_5min</th>\n",
       "      <th>mother_age</th>\n",
       "      <th>father_age</th>\n",
       "      <th>gestation_weeks</th>\n",
       "      <th>ever_born</th>\n",
       "      <th>mother_married</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1984</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.251004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1980</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.436599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1983</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>21</td>\n",
       "      <td>26</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.311835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1985</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>39.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8.000575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1979</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>17</td>\n",
       "      <td>99</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.876218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  plurality  apgar_5min  mother_age  father_age  gestation_weeks  \\\n",
       "0  1984        1.0        10.0          18          22             38.0   \n",
       "1  1980        1.0         9.0          16          17             99.0   \n",
       "2  1983        1.0         8.0          21          26             38.0   \n",
       "3  1985        1.0         9.0          30          30             39.0   \n",
       "4  1979        1.0        10.0          17          99             39.0   \n",
       "\n",
       "   ever_born  mother_married    weight  \n",
       "0        1.0               1  7.251004  \n",
       "1        1.0               0  5.436599  \n",
       "2        2.0               1  6.311835  \n",
       "3        3.0               1  8.000575  \n",
       "4        1.0               0  6.876218  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "client = bigquery.Client()\n",
    "\n",
    "sql = \"\"\"\n",
    "    SELECT \n",
    "        year,\n",
    "        plurality, \n",
    "        apgar_5min,\n",
    "        mother_age, \n",
    "        father_age,    \n",
    "        gestation_weeks, \n",
    "        ever_born,\n",
    "        CASE WHEN mother_married = true THEN 1 ELSE 0 END AS mother_married,\n",
    "        weight_pounds AS weight\n",
    "    FROM\n",
    "        `bigquery-public-data.samples.natality`\n",
    "    ORDER BY\n",
    "        RAND()\n",
    "    LIMIT\n",
    "        10000\n",
    "\"\"\"\n",
    "\n",
    "natality_df = client.query(sql).to_dataframe().fillna(0)\n",
    "natality_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from google.cloud import storage\n",
    "\n",
    "# fit and pickle a model \n",
    "model = LinearRegression()\n",
    "model.fit(natality_df.drop(columns='weight'), natality_df['weight'])\n",
    "joblib.dump(model, 'natality.pkl')\n",
    "\n",
    "# Save to GCS\n",
    "bucket = storage.Client().get_bucket('dsp_model_store_00')\n",
    "blob = bucket.blob('natality/sklearn-linear')\n",
    "blob.upload_from_filename('natality.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "from google.cloud import storage\n",
    "\n",
    "bucket = storage.Client().get_bucket('dsp_model_store_00')\n",
    "blob = bucket.get_blob('natality/sklearn-linear')\n",
    "blob.download_to_filename('sklearn-linear')\n",
    "model = joblib.load('sklearn-linear')\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BigQuery Publish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing scripts/apply.py\n"
     ]
    }
   ],
   "source": [
    "%%file scripts/apply.py\n",
    "\n",
    "import json\n",
    "import argparse\n",
    "import apache_beam as beam\n",
    "from apache_beam.options.pipeline_options import PipelineOptions\n",
    "from apache_beam.options.pipeline_options import SetupOptions\n",
    "from apache_beam.io.gcp.bigquery_tools import parse_table_schema_from_json\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT \n",
    "        year,\n",
    "        plurality, \n",
    "        apgar_5min,\n",
    "        mother_age, \n",
    "        father_age,    \n",
    "        gestation_weeks, \n",
    "        ever_born,\n",
    "        CASE WHEN mother_married = true THEN 1 \n",
    "             ELSE 0\n",
    "        END AS mother_married,\n",
    "        weight_pounds AS weight,\n",
    "        CURRENT_TIMESTAMP AS time,\n",
    "        GENERATE_UUID() AS guid\n",
    "    FROM\n",
    "        `bigquery-public-data.samples.natality`\n",
    "    LIMIT\n",
    "        100\n",
    "\"\"\"\n",
    "\n",
    "class ApplyDoFn(beam.DoFn):\n",
    "\n",
    "    def __init__(self):\n",
    "        import joblib\n",
    "        import pandas as pd\n",
    "        from google.cloud import storage\n",
    "        self._model = None\n",
    "        self._storage = storage\n",
    "        self._joblib = joblib\n",
    "        self._pd = pd\n",
    "     \n",
    "    def process(self, element):\n",
    "        if self._model is None:\n",
    "            bucket = self._storage.Client().get_bucket('dsp_model_store_00')\n",
    "            blob = bucket.get_blob('natality/sklearn-linear')\n",
    "            blob.download_to_filename('sklearn-linear')\n",
    "            self._model = self._joblib.load('sklearn-linear')\n",
    "        \n",
    "        new_x = self._pd.DataFrame.from_dict(element, orient=\"index\").T.fillna(0)   \n",
    "        weight = self._model.predict(new_x.iloc[:, :8])[0]\n",
    "        return [{'guid': element['guid'],\n",
    "                 'weight': weight,\n",
    "                 'time': str(element['time'])}]\n",
    "\n",
    "schema = parse_table_schema_from_json(json.dumps({\n",
    "    'fields': [{'name': 'guid', 'type': 'STRING'},\n",
    "               {'name': 'weight', 'type': 'FLOAT64'},\n",
    "               {'name': 'time', 'type': 'STRING'}]\n",
    "}))\n",
    "\n",
    "# set up pipeline options\n",
    "parser = argparse.ArgumentParser()\n",
    "known_args, pipeline_args = parser.parse_known_args()\n",
    "pipeline_options = PipelineOptions(pipeline_args)\n",
    "\n",
    "# define the pipeline steps\n",
    "p = beam.Pipeline(options=pipeline_options)\n",
    "data = p | 'Read from BigQuery' >> beam.io.ReadFromBigQuery(\n",
    "    query=query, \n",
    "    use_standard_sql=True\n",
    ")\n",
    "scored = data | 'Apply Model' >> beam.ParDo(ApplyDoFn())\n",
    "scored | 'Save to BigQuery' >> beam.io.WriteToBigQuery(\n",
    "    table='weight_preds',\n",
    "    dataset='dsp_demo', \n",
    "    schema=schema,\n",
    "    create_disposition=beam.io.BigQueryDisposition.CREATE_IF_NEEDED,\n",
    "    write_disposition=beam.io.BigQueryDisposition.WRITE_APPEND\n",
    ")\n",
    "\n",
    "# run the pipeline\n",
    "result = p.run()\n",
    "result.wait_until_finish()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# running locally\n",
    "python3 scripts/apply.py \\\n",
    "    --project $GOOGLE_PROJECT_ID \\\n",
    "    --temp_location gs://dsp_model_store_00/tmp/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import apache_beam as beam\n",
    "# import argparse\n",
    "# from apache_beam.options.pipeline_options import PipelineOptions\n",
    "# from apache_beam.options.pipeline_options import SetupOptions\n",
    "# from apache_beam.io.gcp.bigquery import parse_table_schema_from_json\n",
    "# import json\n",
    "\n",
    "# query = \"\"\"\n",
    "#     SELECT year, plurality, apgar_5min, \n",
    "#     mother_age, father_age,    \n",
    "#        gestation_weeks, ever_born\n",
    "#        ,case when mother_married = true \n",
    "#           then 1 else 0 end as mother_married\n",
    "#       ,weight_pounds as weight\n",
    "#       ,current_timestamp as time\n",
    "#       ,GENERATE_UUID() as guid\n",
    "#     FROM `bigquery-public-data.samples.natality` \n",
    "#     limit 100    \n",
    "# \"\"\"\n",
    "\n",
    "# class ApplyDoFn(beam.DoFn):\n",
    "\n",
    "#     def __init__(self):\n",
    "#         self._model = None\n",
    "#         from google.cloud import storage\n",
    "#         import pandas as pd\n",
    "#         import pickle as pkl\n",
    "#         self._storage = storage\n",
    "#         self._pkl = pkl\n",
    "#         self._pd = pd\n",
    "     \n",
    "#     def process(self, element):\n",
    "#         if self._model is None:\n",
    "#             bucket = self._storage.Client().get_bucket('dsp_model_store')\n",
    "#             blob = bucket.get_blob('natality/sklearn-linear')\n",
    "#             self._model = self._pkl.loads(blob.download_as_string())\n",
    "        \n",
    "#         new_x = self._pd.DataFrame.from_dict(element, orient=\"index\").T.fillna(0)   \n",
    "#         weight = self._model.predict(new_x.iloc[:,1:8])[0]\n",
    "#         return [{'guid': element['guid'], \n",
    "#                  'weight': weight, \n",
    "#                  'time': str(element['time'])}]\n",
    "\n",
    "# schema = parse_table_schema_from_json(json.dumps({'fields':\n",
    "#             [ { 'name': 'guid', 'type': 'STRING'},\n",
    "#               { 'name': 'weight', 'type': 'FLOAT64'},\n",
    "#               { 'name': 'time', 'type': 'STRING'} ]}))\n",
    "\n",
    "# class PublishDoFn(beam.DoFn):\n",
    "    \n",
    "#     def __init__(self):\n",
    "#         from google.cloud import datastore       \n",
    "#         self._ds = datastore\n",
    "    \n",
    "#     def process(self, element):\n",
    "#         client = self._ds.Client()\n",
    "#         key = client.key('natality-guid', element['guid'])\n",
    "#         entity = self._ds.Entity(key)\n",
    "#         entity['weight'] = element['weight']         \n",
    "#         entity['time'] = element['time']\n",
    "#         client.put(entity)\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# known_args, pipeline_args = parser.parse_known_args(None)\n",
    "# pipeline_options = PipelineOptions(pipeline_args)\n",
    "\n",
    "# # define the pipeline steps\n",
    "# p = beam.Pipeline(options=pipeline_options)\n",
    "# data = p | 'Read from BigQuery' >> beam.io.Read(\n",
    "#        beam.io.BigQuerySource(query=query, use_standard_sql=True))\n",
    "# scored = data | 'Apply Model' >> beam.ParDo(ApplyDoFn())\n",
    "# scored | 'Save to BigQuery' >> beam.io.Write(beam.io.BigQuerySink(\n",
    "#                 'weight_preds', 'dsp_demo', schema = schema,\n",
    "#                 create_disposition=beam.io.BigQueryDisposition.CREATE_IF_NEEDED,\n",
    "#                 write_disposition=beam.io.BigQueryDisposition.WRITE_APPEND))\n",
    "\n",
    "# scored | 'Create entities' >> beam.ParDo(PublishDoFn())\n",
    "\n",
    "# # run the pipeline\n",
    "# result = p.run()\n",
    "# result.wait_until_finish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read from Datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Entity('natality-guid', '0046cdef-6a0f-4586-86ec-4b995cfc7c4e') {'weight': 7.9434742419056, 'time': '2019-12-15 03:00:06.319496 UTC'}>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from google.cloud import datastore\n",
    "client = datastore.Client()\n",
    "query = client.query(kind='natality-guid')\n",
    "\n",
    "query_iter = query.fetch()\n",
    "for entity in query_iter:\n",
    "    print(entity)\n",
    "    break\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
